{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "hands=mp_hands.Hands(max_num_hands=1,min_detection_confidence=0.7)\n",
    "mp_drawing = mp.solutions.drawing_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the video capture\n",
    "cap = cv2.VideoCapture(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state (hand_landmarks,frame):\n",
    "    # Detecting hand state\n",
    "\n",
    "                wrist = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]\n",
    "                index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "\n",
    "\n",
    "                index_finger_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP]\n",
    "                \n",
    "                \n",
    "                # f.write(str(index_finger_tip.x) + \",\" + str(wrist.x)+ \",\" + str(index_finger_tip.x-wrist.x)  + \"\\n\")\n",
    "\n",
    "                for_back=0\n",
    "                left_right=0\n",
    "                #open are close\n",
    "                if (index_finger_mcp.y>index_finger_tip.y):\n",
    "                    for_back=1\n",
    "                    \n",
    "                else:\n",
    "                    for_back=2\n",
    "\n",
    "                # #left are right\n",
    "                if ((index_finger_tip.x-wrist.x)<-.20):\n",
    "                    left_right=3    \n",
    "                elif ((index_finger_tip.x-wrist.x)>.05):\n",
    "                    left_right=4\n",
    "                \n",
    "\n",
    "                return for_back,left_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_state_changed(new_for_back,new_left_right,old_for_back,old_left_right):\n",
    "    direction=[' ','w','s','a','d']\n",
    "    if old_for_back==old_left_right==0:\n",
    "        keyboard.press(direction[new_for_back])\n",
    "        if  old_left_right != 0:\n",
    "            keyboard.press(direction[old_left_right])\n",
    "        return False\n",
    "    elif new_for_back==old_for_back and new_left_right==old_left_right:\n",
    "        return False\n",
    "    else: return True   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\study\\codes\\engineering_codes\\research\\conda_env_for_project\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "#opening excel sheet\n",
    "from ast import And\n",
    "from calendar import c\n",
    "from hmac import new\n",
    "from math import pi\n",
    "direction=[' ' ,'w','s','a','d']\n",
    "old_for_back=0\n",
    "old_left_right=0\n",
    "f = open(\"coordinaates.csv\", \"w\")\n",
    "while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the frame with MediaPipe Hands\n",
    "        results = hands.process(rgb_frame)\n",
    "        if results.multi_hand_landmarks:                     #it means that the MediaPipe Hands model has detected one or more hands in the frame\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame,\n",
    "                    hand_landmarks,\n",
    "                    mp_hands.HAND_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2),\n",
    "                    mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2)\n",
    "                )\n",
    "                \n",
    "                \n",
    "                new_for_back,new_left_right=state(hand_landmarks,frame)\n",
    "                if is_state_changed( new_for_back,new_left_right,old_for_back,old_left_right):\n",
    "                    if old_for_back!=0 and old_left_right!=0:\n",
    "                        keyboard.release(direction[old_for_back],direction[old_left_right])\n",
    "                    elif old_for_back!=0:\n",
    "                        keyboard.release(direction[old_for_back])\n",
    "                    elif old_left_right!=0:\n",
    "                        keyboard.release(direction[old_left_right])\n",
    "                    \n",
    "                    if new_for_back!=0 and new_left_right!=0:\n",
    "                        keyboard.press(direction[new_for_back],direction[new_left_right])\n",
    "                    elif new_for_back!=0:\n",
    "                        keyboard.press(direction[new_for_back])\n",
    "                    elif new_left_right!=0:\n",
    "                        keyboard.press(direction[new_left_right])\n",
    "                            \n",
    "\n",
    "\n",
    "                        #\n",
    "                    old_for_back=new_for_back\n",
    "                    old_left_right=new_left_right\n",
    "                # cv2.putText(frame, str(for_back), (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2, cv2.LINE_AA)\n",
    "                # cv2.putText(frame, str(left_right), (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "        # Display the frame\n",
    "        cv2.imshow('MediaPipe Hand Gesture', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "f.close()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
